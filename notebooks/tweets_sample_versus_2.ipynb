{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import shelve\n",
    "\n",
    "from twnews.utils.memoize import load\n",
    "from twnews.dataset.storage import TweetsStorage, NewsStorage\n",
    "from twnews.dataset.url_resolver import UrlResolver\n",
    "from twnews.dataset.texts import Tweet\n",
    "from twnews import defaults\n",
    "from twnews.utils.text_processors import Lemmatizer\n",
    "from twnews.resolver import get_domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-05-08 19:34:19.048693: Start of loading url_map from /home/avybornov/twnews_data_april/resolve_url_map.shelve\n",
      "2016-05-08 19:34:19.050078: Url map successfully loaded\n"
     ]
    }
   ],
   "source": [
    "corpus, _  = load('tf_idf_corpus')\n",
    "corpus = set(corpus)\n",
    "lemmatizer = Lemmatizer()\n",
    "data_shelve = shelve.open(defaults.TWEETS_PATH)\n",
    "resolver = UrlResolver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00%\n",
      "2.02%\n",
      "4.04%\n",
      "6.05%\n",
      "8.07%\n",
      "10.09%\n",
      "12.11%\n",
      "14.13%\n",
      "16.14%\n",
      "18.16%\n",
      "20.18%\n",
      "22.20%\n",
      "24.22%\n",
      "26.23%\n",
      "28.25%\n",
      "30.27%\n",
      "32.29%\n",
      "34.31%\n",
      "36.32%\n",
      "38.34%\n",
      "40.36%\n",
      "42.38%\n",
      "44.39%\n",
      "46.41%\n",
      "48.43%\n",
      "50.45%\n",
      "52.47%\n",
      "54.48%\n",
      "56.50%\n",
      "58.52%\n",
      "60.54%\n",
      "62.56%\n",
      "64.57%\n",
      "66.59%\n",
      "68.61%\n",
      "70.63%\n",
      "72.65%\n",
      "74.66%\n",
      "76.68%\n",
      "78.70%\n",
      "80.72%\n",
      "82.74%\n",
      "84.75%\n",
      "86.77%\n",
      "88.79%\n",
      "90.81%\n",
      "92.83%\n",
      "94.84%\n",
      "96.86%\n",
      "98.88%\n"
     ]
    }
   ],
   "source": [
    "keys = data_shelve.keys()\n",
    "random.shuffle(keys)\n",
    "\n",
    "tweets = []\n",
    "for i, key in enumerate(keys):\n",
    "    tweet = Tweet(data_shelve[key])\n",
    "    tweet.resolve_urls(resolver)\n",
    "    tweets.append(tweet)\n",
    "    \n",
    "    if i % 10000 == 0:\n",
    "        print '%.2f%%' % (i*100.0/len(keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "news_storage = NewsStorage()\n",
    "news_documents = news_storage.get_dataset_texts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "путин\n",
      "владимир\n"
     ]
    }
   ],
   "source": [
    "def _extract_entities(text):\n",
    "    t = Text(text)\n",
    "    t.language = 'ru'\n",
    "    ent = t.entities\n",
    "    res = []\n",
    "    for e in ent:\n",
    "        #print '\\t',e\n",
    "        for x in e:\n",
    "            x_l = lemmatizer.lemmatize(x)\n",
    "            #print '\\t\\t', x.lower()\n",
    "            res.append(x_l)\n",
    "    return set(res)\n",
    "for x in _extract_entities('Владимир Путин блаблабла'): print x\n",
    "#    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00%\n",
      "7.29%\n",
      "14.59%\n",
      "21.88%\n",
      "29.17%\n",
      "36.47%\n",
      "43.76%\n",
      "51.05%\n",
      "58.35%\n",
      "65.64%\n",
      "72.93%\n",
      "80.23%\n",
      "87.52%\n",
      "94.81%\n"
     ]
    }
   ],
   "source": [
    "from polyglot.text import Text\n",
    "total_news_NE = set()\n",
    "errors = 0\n",
    "for i, news in enumerate(news_documents):\n",
    "    text = news.title + '. ' + news.summary\n",
    "    try:\n",
    "        ents = _extract_entities(text)\n",
    "    except Exception:\n",
    "        errors += 1\n",
    "        ents = set()\n",
    "    news.entitites = ents\n",
    "    #print ents\n",
    "    #for x in ents: print '\\t', x\n",
    "    #ents = map(lambda x: x.tolower(), ents)\n",
    "    #print total_news_NE\n",
    "    #for x in ents: print '\\t', x\n",
    "\n",
    "    total_news_NE.update(ents)\n",
    "    \n",
    "    if i % 1000 == 0:\n",
    "        print '%.2f%%' % (i*100.0/len(news_documents))\n",
    "\n",
    "#     for x in ents:\n",
    "#         print x\n",
    "    \n",
    "#     print ent\n",
    "\n",
    "#     print news.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "9072\n",
      "<type 'str'> Путин False\n",
      "<type 'unicode'> Путин False\n",
      "<type 'unicode'> путин True\n",
      "495552\n"
     ]
    }
   ],
   "source": [
    "print errors\n",
    "print len(total_news_NE)\n",
    "for putin in ['Путин', u'Путин', u'путин']:\n",
    "    print putin.__class__, putin,\n",
    "    print putin in total_news_NE\n",
    "\n",
    "# for x in list(total_news_NE)[:100]:\n",
    "#     print x\n",
    "print len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "already_marked = set([])\n",
    "files = ['random_500/random_result', '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Станислав Белковский: Базовая идея Владимира Путина состоит в том, что Украина все равно развалится и рухнет \n",
      "['http://www.svoboda.org/content/transcript/27668832.html']\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "bad_domain = set(['apps.facebook.com', 'ask.fm', 'twitter.com', 'apps.facebook.com', 'www.instagram.com', 'www.instagram.com', 'vk.cc'])\n",
    "min_num_of_words_in_NE = 2\n",
    "already_marked = load('already_marked')\n",
    "def is_tweet_good(tweet):\n",
    "    if tweet.retweet:\n",
    "        return False\n",
    "    \n",
    "    if tweet.tweet_id in already_marked:\n",
    "        return False\n",
    "    \n",
    "    for url in tweet.urls:\n",
    "        domain = get_domain(url)\n",
    "        if domain in bad_domain:\n",
    "            return False\n",
    "        \n",
    "    text = tweet.text\n",
    "    \n",
    "#     for h in tweet.hastags:\n",
    "#         text = text.replace(h, '')\n",
    "    \n",
    "    words = lemmatizer.split_text_to_lemmas(text)\n",
    "    \n",
    "    #print map(lambda x: x.__class__, words)\n",
    "    #words = map(lambda x: x.decode('utf-8'), words)\n",
    "#     if len(words) < min_num_of_words:\n",
    "#         return False\n",
    "    \n",
    "    num_of_words_in_NE = sum(map(lambda x: x in total_news_NE, words))\n",
    "    if num_of_words_in_NE < min_num_of_words_in_NE:\n",
    "        return False\n",
    "    tweet.num_of_words_in_NE = num_of_words_in_NE\n",
    "    \n",
    "    return True\n",
    "\n",
    "def filtration(tweets):\n",
    "    res = []\n",
    "    for i, tweet in enumerate(tweets):\n",
    "        if is_tweet_good(tweet):\n",
    "            res.append(tweet)\n",
    "        if i % 5000 == 0:\n",
    "            print '%.2f%%' % (i*100.0/len(tweets))\n",
    "    print len(tweets), len(res)\n",
    "    return res\n",
    "\n",
    "print tweets[0]\n",
    "print tweets[0].urls\n",
    "print is_tweet_good(tweets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00%\n",
      "10.00%\n",
      "20.00%\n",
      "30.00%\n",
      "40.00%\n",
      "50.00%\n",
      "60.00%\n",
      "70.00%\n",
      "80.00%\n",
      "90.00%\n",
      "50000 13666\n",
      "13666\n"
     ]
    }
   ],
   "source": [
    "good_tweets = filtration(tweets[:50000])\n",
    "print len(good_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "words_distribution = defaultdict(list)\n",
    "for tweet in good_tweets:\n",
    "    k = tweet.num_of_words_in_NE\n",
    "    words_distribution[k].append(tweet.text)\n",
    "   # print tweet\n",
    "good_tweets_1 = filter(lambda x: x.num_of_words_in_NE >= 2, good_tweets)[:10000]    \n",
    "print len(good_tweets_1)\n",
    "# words_distribution = sorted(words_distribution.items(), key=lambda x: len(x[1]), reverse=True)\n",
    "# for k, texts in words_distribution:\n",
    "#     print k, len(texts)\n",
    "#     for x in texts[:10]:\n",
    "#         print '\\t',x.replace('\\n', ' ')[:80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for tweet in tweets[:20]:\n",
    "#     print tweet\n",
    "#     good = is_tweet_good(tweet)\n",
    "#     if good: print tweet.num_of_words_in_NE\n",
    "#     #print '----'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from twnews.utils.memoize import dump\n",
    "\n",
    "dump(good_tweets_1, 'tweet_filtered_versus_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
