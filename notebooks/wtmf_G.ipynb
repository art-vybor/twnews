{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from twnews.utils.memoize import load\n",
    "import logging\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "from twnews.timeit import timeit\n",
    "from twnews.utils.memoize import memo_process, load, dump\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18035 25290\n"
     ]
    }
   ],
   "source": [
    "dataset = load('dataset')\n",
    "links = dataset.text_to_text_links\n",
    "corpus, tf_idf_matrix = load('tf_idf_corpus')\n",
    "lemmatized_texts = load('lemmatized_texts')\n",
    "news_num = dataset.news.length()\n",
    "documents = dataset.get_dataset_texts()\n",
    "\n",
    "print len(lemmatized_texts), len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print links\n",
    "from collections import defaultdict\n",
    "text_to_text = defaultdict(set)\n",
    "for i,j in links:\n",
    "    text_to_text[i].add(j)\n",
    "    text_to_text[j].add(i)\n",
    "    \n",
    "# for i in text_to_text:\n",
    "#     print i, text_to_text[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def get_matrix_slice_by_column(M, indexes):\n",
    "    length, width = M.shape\n",
    "    \n",
    "    #dim = len(corpus)\n",
    "\n",
    "    data, row_idxs, column_idxs = [], [], []\n",
    "    for column_idx, idx in enumerate(indexes):\n",
    "        rows, _, values = sparse.find(M[:,idx])\n",
    "        for i, value in enumerate(values):\n",
    "            data.append(values[i])\n",
    "            row_idxs.append(rows[i])\n",
    "            column_idxs.append(column_idx)\n",
    "\n",
    "    compare_matrix = sparse.csr_matrix((data, (row_idxs, column_idxs)), shape=(length, len(indexes)))\n",
    "    return compare_matrix\n",
    "\n",
    "def get_vector_length(v):    \n",
    "    idxs, _, value = sparse.find(v)\n",
    "    sumxx = 0\n",
    "    for i in idxs:\n",
    "        x = v[(i,i)]\n",
    "        sumxx += x*x\n",
    "    return math.sqrt(sumxx*1.0)\n",
    "    #return np.sqrt((v*v).sum()) \n",
    "\n",
    "def get_vectors_length_array(M):\n",
    "    res = []\n",
    "    for i in range(M.shape[1]):\n",
    "        res.append(get_vector_length(M[:,i]))\n",
    "    return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class WTMFG:\n",
    "    def __init__(self,\n",
    "                 texts,\n",
    "                 corpus,\n",
    "                 tf_idf_matrix,\n",
    "                 wm=1e-2,\n",
    "                 dim=3,\n",
    "                 iterations_num=1,\n",
    "                 lmbd=20,\n",
    "                 delta = 0.1,\n",
    "                 try_to_load=False,                 \n",
    "                 ):\n",
    "        self.texts = texts\n",
    "        self.words = corpus\n",
    "        self.X = tf_idf_matrix\n",
    "        self.wm = wm\n",
    "        self.dim = dim\n",
    "        self.iterations_num = iterations_num\n",
    "        self.lmbd = lmbd\n",
    "        self.delta = delta\n",
    "        self.try_to_load=try_to_load\n",
    "        self.P = None\n",
    "        self.Q = None\n",
    "        self.model_filename = 'model_%s_%s' % (self.iterations_num, self.dim)\n",
    "        if self.try_to_load:\n",
    "            PQ_loaded = load(self.model_filename)\n",
    "            if PQ_loaded:\n",
    "                self.P, self.Q = PQ_loaded\n",
    "\n",
    "    def __str__(self):\n",
    "        return 'model(wm={wm}, dim={dim}, iter={iter}, lambda={lmbd}, texts={len_texts})'.format(\n",
    "            wm=self.wm,\n",
    "            dim=self.dim,\n",
    "            iter=self.iterations_num,\n",
    "            lmbd=self.lmbd,\n",
    "            len_texts=len(self.texts),\n",
    "        )\n",
    "\n",
    "    def init_PQ(self):\n",
    "        P = np.random.rand(self.dim, len(self.words))\n",
    "        P = P * 0.2 - 0.1\n",
    "        P = sparse.csr_matrix(P)\n",
    "\n",
    "        Q = np.random.rand(self.dim, len(self.texts))\n",
    "        Q = Q * 0.2 - 0.1\n",
    "        Q = sparse.csr_matrix(Q)\n",
    "\n",
    "        return P, Q\n",
    "\n",
    "    def build(self):\n",
    "        if self.P == None or self.Q == None:\n",
    "            P, Q = self.init_PQ()\n",
    "            X = self.X\n",
    "            W = self.build_weight_matrix(X)\n",
    "            lI = np.identity(self.dim) * self.lmbd\n",
    "\n",
    "            for i in range(self.iterations_num):\n",
    "                print '%d/%d iteration' % (i + 1, self.iterations_num)\n",
    "                P, Q = self.iteration(P, Q, W, X, lI)\n",
    "\n",
    "            dump((P, Q), self.model_filename)\n",
    "            self.P, self.Q = P, Q\n",
    "        else:\n",
    "            logging.warn('Try to build already builded model, breaked')\n",
    "\n",
    "    @timeit\n",
    "    def iteration(self, P, Q, W, X, lI):\n",
    "        #P = self.new_P(P, Q, W, X, lI)\n",
    "        Q = self.new_Q(P, Q, W, X, lI)\n",
    "\n",
    "        return P, Q\n",
    "\n",
    "    def new_Q(self, P, old_Q, W, X, lI):\n",
    "        print 'start build Q'\n",
    "        Q = sparse.csc_matrix(old_Q.shape)\n",
    "        Q_length = get_vectors_length_array(Q)\n",
    "        \n",
    "        for i in range(Q.shape[1]):\n",
    "        #for i in range(100):\n",
    "            Qi = Q[:,i]\n",
    "            #print Qi.shape\n",
    "            LQi = Q_length[i]\n",
    "            #print LQi\n",
    "            \n",
    "            n_i = text_to_text[i]\n",
    "            n_i.add(1)\n",
    "            #print len(n_i)\n",
    "            LQn_i = [Q_length[j] for j in n_i]\n",
    "            #print len(LQn_i)\n",
    "            \n",
    "            Qn_i = get_matrix_slice_by_column(Q, n_i)\n",
    "            #print Qn_i.shape\n",
    "            Q[:, i] = self.build_relation_row(P, W[:, i].T, X[:, i].T, lI, Qi, LQi, Qn_i, LQn_i)\n",
    "\n",
    "            if i % 1000 == 0:\n",
    "                print '%dth iteration of %d' % (i, Q.shape[1])\n",
    "        return Q\n",
    "\n",
    "    def new_P(self, old_P, Q, W, X, lI):\n",
    "        print 'start build P'\n",
    "        P = sparse.csr_matrix(old_P.shape)\n",
    "\n",
    "        #for i in range(P.shape[1]):\n",
    "        for i in range(100):\n",
    "            P[:, i] = self.build_row(Q, W[i, :], X[i, :], lI)\n",
    "\n",
    "            if i % 1000 == 0:\n",
    "                print '%dth iteration of %d' % (i, P.shape[1])\n",
    "        return P\n",
    "\n",
    "    def build_row(self, A, w_row, x_row, lI):\n",
    "        \"\"\"calc (A w_row A^T + lI)^-1 * A * w_row * x_row \"\"\"\n",
    "        w_row_len = max(w_row.shape)\n",
    "        W_i = sparse.spdiags(w_row.A, 0, w_row_len, w_row_len)\n",
    "\n",
    "        AW = A.dot(W_i)\n",
    "        AWA = AW.dot(A.T)\n",
    "        AWAl = AWA + lI\n",
    "        AWAl_inv = sparse.csr_matrix(np.linalg.inv(AWAl))\n",
    "        AWX = AW.dot(x_row.T)\n",
    "\n",
    "        return AWAl_inv.dot(AWX)\n",
    "    \n",
    "    def build_relation_row(self, A, w_row, x_row, lI, Qi, LQi, Qn_i, LQn_i):\n",
    "        \"\"\"calc (A w_row A^T + lI)^-1 * A * w_row * x_row \"\"\"\n",
    "        w_row_len = max(w_row.shape)\n",
    "        W_i = sparse.spdiags(w_row.A, 0, w_row_len, w_row_len)\n",
    "\n",
    "        AW = A.dot(W_i)\n",
    "        AWA = AW.dot(A.T)\n",
    "        AWAl = AWA + lI        \n",
    "        LQn_i_diag = sparse.spdiags(LQn_i, 0, len(LQn_i), len(LQn_i))        \n",
    "        coef_Q_diag_Q = self.delta * LQi ** 2 * Qn_i * LQn_i_diag * Qn_i.T        \n",
    "        AWAl_relation = AWAl + coef_Q_diag_Q.todense()       \n",
    "        AWAl_relation_inv = sparse.csr_matrix(np.linalg.inv(AWAl_relation))\n",
    "        \n",
    "        AWX = AW.dot(x_row.T)\n",
    "        coef_Q_L = Qn_i * sparse.lil_matrix(LQn_i).T * self.delta * LQi\n",
    "        AWX_relation = AWX + coef_Q_L\n",
    "        \n",
    "        return AWAl_relation_inv.dot(AWX_relation)\n",
    "\n",
    "    def apply(self):\n",
    "        P = self.P\n",
    "        Q = sparse.csr_matrix((self.dim, len(self.texts)))\n",
    "\n",
    "        W = self.build_weight_matrix(self.X)\n",
    "        X = self.X\n",
    "        lI = np.identity(self.dim) * self.lmbd\n",
    "\n",
    "        Q = self.new_Q(P, Q, W, X, lI)\n",
    "        return Q\n",
    "\n",
    "    def build_weight_matrix(self, tf_idf_matrix):\n",
    "        nnz_i, nnz_j, elems = sparse.find(tf_idf_matrix)\n",
    "        value = np.zeros(elems.shape[0])\n",
    "        value.fill(self.wm)\n",
    "\n",
    "        r = sparse.coo_matrix((value, (nnz_i, nnz_j)), shape=tf_idf_matrix.shape)\n",
    "        return r.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 iteration\n",
      "start build Q\n",
      "0th iteration of 18035\n",
      "1000th iteration of 18035\n",
      "2000th iteration of 18035\n",
      "3000th iteration of 18035\n",
      "4000th iteration of 18035\n",
      "5000th iteration of 18035\n",
      "6000th iteration of 18035\n",
      "7000th iteration of 18035\n",
      "8000th iteration of 18035\n",
      "9000th iteration of 18035\n",
      "10000th iteration of 18035\n",
      "11000th iteration of 18035\n",
      "12000th iteration of 18035\n",
      "13000th iteration of 18035\n",
      "14000th iteration of 18035\n",
      "15000th iteration of 18035\n",
      "16000th iteration of 18035\n",
      "17000th iteration of 18035\n",
      "18000th iteration of 18035\n"
     ]
    }
   ],
   "source": [
    "model = WTMFG(lemmatized_texts, corpus, tf_idf_matrix, try_to_load=False)\n",
    "model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
