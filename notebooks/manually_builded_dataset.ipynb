{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/avybornov/git/twnews/dataset_markdown/1_filtred_alpha/out\n",
      "/home/avybornov/git/twnews/dataset_markdown/2_filtred_beta/out\n",
      "/home/avybornov/git/twnews/dataset_markdown/3_filtred/0/out\n",
      "/home/avybornov/git/twnews/dataset_markdown/3_filtred/1000/out\n",
      "/home/avybornov/git/twnews/dataset_markdown/3_filtred/2000/out\n",
      "/home/avybornov/git/twnews/dataset_markdown/3_filtred/3000/out\n",
      "/home/avybornov/git/twnews/dataset_markdown/3_filtred/4000/out\n"
     ]
    }
   ],
   "source": [
    "#'random_500/random_result'\n",
    "MARKDOWN_DIR = '/home/avybornov/git/twnews/dataset_markdown/'\n",
    "\n",
    "files = ['1_filtred_alpha/out',\n",
    "         '2_filtred_beta/out',\n",
    "         '3_filtred/0/out',\n",
    "         '3_filtred/1000/out',\n",
    "         '3_filtred/2000/out',\n",
    "         '3_filtred/3000/out',\n",
    "         '3_filtred/4000/out',\n",
    "]\n",
    "tweet_texts = {}\n",
    "news_texts = {}\n",
    "\n",
    "def parse_tweet(rows, idx):\n",
    "    if not rows[idx][0].isdigit(): raise(Exception('Incorrect first row of tweet: %s' % idx))\n",
    "    text = rows[idx]\n",
    "    \n",
    "    idx += 1\n",
    "    #print idx\n",
    "    \n",
    "    while not rows[idx][0].isdigit():\n",
    "        text += ' ' + rows[idx]\n",
    "        idx += 1\n",
    "    \n",
    "    if not rows[idx][0].isdigit(): raise(Exception('Incorrect second row of tweet: %s' % idx))    \n",
    "    tweet_id = int(rows[idx])\n",
    "    idx += 1\n",
    "        \n",
    "    while rows[idx][0] != '\\t':\n",
    "        if rows[idx][:4] != 'http': raise(Exception('Incorrect row with link of tweet: %s' % idx))\n",
    "        idx += 1\n",
    "        \n",
    "    tweet_texts[tweet_id] = text\n",
    "    return idx, tweet_id\n",
    "\n",
    "\n",
    "def parse_news(rows, idx):\n",
    "    marked = False\n",
    "    \n",
    "    if rows[idx][0] != '\\t': raise(Exception('News row started without tabulation: %s' % idx))    \n",
    "    if rows[idx][1] == \"!\": marked = True\n",
    "    text = rows[idx]\n",
    "    idx += 1    \n",
    "    \n",
    "    if rows[idx][0] != '\\t': raise(Exception('News row started without tabulation: %s' % idx))    \n",
    "    if rows[idx][1:5] != 'http': raise(Exception('Incorrect row with link of news: %s' % idx))    \n",
    "    link = rows[idx][1:]\n",
    "    idx += 1\n",
    "    \n",
    "    #print rows[idx]\n",
    "    if rows[idx][1] != \"-\": raise(Exception('Incorrect row with news separator: %s' % idx))        \n",
    "    idx += 1\n",
    "    \n",
    "    if marked: news_texts[link] = text\n",
    "    return idx, link if marked else None\n",
    "\n",
    "\n",
    "def parse_all_news(rows, idx):\n",
    "    news_link = None\n",
    "    \n",
    "    #print rows[idx] == '\\t'\n",
    "    while idx < len(rows) and rows[idx] and rows[idx][0] == '\\t':\n",
    "        idx, link = parse_news(rows, idx)\n",
    "        if link and not news_link:\n",
    "            news_link = link        \n",
    "        \n",
    "    return idx, news_link\n",
    "\n",
    "tweet_to_news = {}\n",
    "for file_suffix in files:\n",
    "    filepath = MARKDOWN_DIR + file_suffix\n",
    "    print filepath\n",
    "    rows = open(filepath).read().splitlines()\n",
    "    \n",
    "    tweet_to_news[file_suffix] = {}\n",
    "    idx = 0\n",
    "    while idx < len(rows):\n",
    "        idx, tweet_id = parse_tweet(rows, idx)\n",
    "        idx, news_link = parse_all_news(rows, idx)\n",
    "        tweet_to_news[file_suffix][tweet_id] = news_link\n",
    "        \n",
    "        #print idx\n",
    "#         if idx > 40:\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2_filtred_beta/out 1173\n",
      "linked: 254 21.65%\n",
      "3_filtred/2000/out 1000\n",
      "linked: 168 16.80%\n",
      "3_filtred/3000/out 1000\n",
      "linked: 171 17.10%\n",
      "3_filtred/1000/out 1000\n",
      "linked: 150 15.00%\n",
      "3_filtred/4000/out 1000\n",
      "linked: 146 14.60%\n",
      "3_filtred/0/out 1000\n",
      "linked: 172 17.20%\n",
      "1_filtred_alpha/out 1200\n",
      "linked: 555 46.25%\n"
     ]
    }
   ],
   "source": [
    "already_marked = set([])\n",
    "\n",
    "linked_for_files = {}\n",
    "\n",
    "for file_suffix, data in tweet_to_news.iteritems():\n",
    "    print file_suffix, len(data)\n",
    "    linked = {}\n",
    "    for tweet_id, link in data.items():\n",
    "        already_marked.add(tweet_id)\n",
    "        if link: linked[tweet_id] = link\n",
    "    linked_for_files[file_suffix] = linked\n",
    "    print 'linked: %s %.2f%%' % (len(linked), len(linked)*100.0/len(data))\n",
    "        #print '\\t', 'https://twitter.com/statuses/%s' % tweet_id, link\n",
    "        \n",
    "from twnews.utils.memoize import dump\n",
    "dump(already_marked, 'already_marked')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3_filtred/4000/out\n",
      "\t655) #kp_ru Замгенпрокурора прилетел с проверкой на рыбокомбинат на острове Шикотан  #news\n",
      "\t\t!Замгенпрокурора проверил цеха рыбокомбината на острове Шикотан\n",
      "\t524) Участники референдума в Нидерландах не знают, где находится Украина – СМИ\n",
      "\t\t!Участники референдума в Нидерландах не смогли найти Украины на карте\n",
      "\t106) 16 апреля  пройдет Тотальный диктант\n",
      "\t\t!Акция по проверке знаний русского языка \"Тотальный диктант\"\n",
      "\t501) «Боруссия» и «Ливерпуль» разошлись миром в матче четвертьфинала ЛЕ: Соперничество дортмундской «Боруссии» и ан... \n",
      "\t\t!\"Боруссия\" и \"Ливерпуль\" разошлись миром в матче четвертьфинала ЛЕ\n",
      "\t694) Введение в оборот в России новых банкнот достоинством 200 и 2000 рублей объясняется инфляцией в стране. Об этом заявил бывший председатель Ц\n",
      "\t\t!ЦБ РФ выпустит банкноты достоинством 2000 и 200 рублей\n",
      "\t702) Азербайджан обвинил армянских военных в нарушении перемирия \n",
      "\t\t!Минобороны Азербайджана обвинило Армению в нарушении перемирия\n",
      "\t754) Голосование на парламентских выборах в Сирии. ФОТОЛЕНТА  \n",
      "\t\t!Голосование на парламентских выборах в Сирии\n",
      "\t235) США поблагодарили РФ за освобождение американца в Сирии\n",
      "\t\t!США поблагодарили Россию за помощь в освобождении американца в Сирии\n",
      "\t933) В Турции заблокировали сайт российского агентства Sputnik\n",
      "\t\t!Сайт агентства Sputnik заблокирован в Турции\n",
      "\t867) #новости #общество Актер из «Бригады» Дмитрий Гуменицкий осужден на 8 лет за наркотики  \n",
      "\t\t!Актер из «Бригады» осужден на восемь лет за спайс\n",
      "\t177) Савченко начала сухую голодовку \n",
      "\t\t!Надежда Савченко начала сухую голодовку\n",
      "\t611) Порошенко: соглашение об ассоциации с ЕС не будет изменено после референдума в Нидерландах \n",
      "\t\t!Пётр Порошенко: Ассоциации Украины с ЕС не буде изменено, несмотря на референдум в Нидерландах\n",
      "\t796) В России появятся «быстрые» фирменные зарядки Tesla \n",
      "\t\t!Tesla может построить в России cеть заправок в этом году\n",
      "\t269) Нидерланды могут отказаться от ратификации соглашения Украина-ЕС  #общество\n",
      "\t\t!Голландский премьер заявил о невозможности ратификации соглашения  с Украиной\n",
      "\t791) Британский премьер обнародовал данные о своих доходах \n",
      "\t\t!Кэмерон раскрыл декларацию о своих доходах\n",
      "\t937) Жительница Дагестана убила около 80 змей на своем участке... \n",
      "\t\t!В Дагестане пенсионерка лопатой убила 80 заползших в огород змей\n",
      "\t184) Президент видит Гройсмана новым премьер-министром \n",
      "\t\t!Порошенко предложил Раде назначить Гройсмана премьер-министром\n",
      "\t955) Хабаровский театр покажет мюзикл о дружбе козла Тимура и тигра Амура  :\n",
      "\t\t!В Хабаровске покажут мюзикл о дружбе Тимура и Амура\n",
      "\t483) В России вновь завели уголовное дело на компанию IKEA\n",
      "\t\t!В России вновь завели уголовное дело на компанию IKEA\n",
      "\t204) Президент РФ о своём участии в президентских выборах 2018 \n",
      "\t\t!Путин: об участии в президентских выборах 2018 года говорить рано\n"
     ]
    }
   ],
   "source": [
    "for file_suffix, data in linked_for_files.items()[-3:-2]:\n",
    "    print file_suffix\n",
    "    for tweet_id, link in data.items()[:20]:\n",
    "        print '\\t',tweet_texts[tweet_id]\n",
    "        print '\\t',news_texts[link]\n",
    "\n",
    "#print len(already_marked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-05-11 21:18:57.432558: Start of loading url_map from /home/avybornov/twnews_data_april/resolve_url_map.shelve\n",
      "2016-05-11 21:18:57.432914: Url map successfully loaded\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import shelve\n",
    "\n",
    "from twnews.utils.memoize import load\n",
    "from twnews.dataset.storage import TweetsStorage, NewsStorage\n",
    "from twnews.dataset.url_resolver import UrlResolver\n",
    "from twnews.dataset.texts import Tweet\n",
    "from twnews import defaults\n",
    "from twnews.utils.text_processors import Lemmatizer\n",
    "from twnews.resolver import get_domain\n",
    "corpus, _  = load('tf_idf_corpus')\n",
    "corpus = set(corpus)\n",
    "lemmatizer = Lemmatizer()\n",
    "data_shelve = shelve.open(defaults.TWEETS_PATH)\n",
    "resolver = UrlResolver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "for file_suffix, data in linked_for_files.items():\n",
    "    filepath = MARKDOWN_DIR+file_suffix\n",
    "    dirname, filename = os.path.dirname(filepath), os.path.basename(filepath)\n",
    "\n",
    "    tweets = []\n",
    "    for tweet_id, link in data.items():\n",
    "        tweet = Tweet(data_shelve[str(tweet_id)])\n",
    "        tweet.resolve_urls(resolver)\n",
    "        tweet.urls.append(link)\n",
    "        tweets.append(tweet)\n",
    "        \n",
    "    dump(tweets, 'manual_tweets', dirname)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
