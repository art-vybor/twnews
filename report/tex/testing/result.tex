\subsection{Сравнительные результаты}
    Для выявления влияния добавления связей текст-текст на результаты работы метода WMTF-G производится сравнительное тестирование алгоритма WTMF и WTMF-G. Тестирование производится для различных наборов данных.
    Результаты тестирования приведены в таблице~\ref{tabular:wtmf_wmtfg}.

    \begin{table}[h!]
    %\small
    \caption{Cравнительное тестирование алгоритмов WTMF и WTMF-G. \bigskip}
    \centering

    \label{tabular:wtmf_wmtfg}
        \begin{tabular}{|c|c|c|c|c|c|c|}
            \hline
            \bf{\multirow{2}{*}{\specialcell{Набор данных}}} &
            \multicolumn{2}{|c|}{\bf{Метрика MRR}} &
            \multicolumn{2}{|c|}{\bf{Метрика $TOP_1$}} &
            \multicolumn{2}{|c|}{\bf{Метрика $TOP_3$}} \\ \cline{2-7}
            & \bf{WTMF} & \bf{WTMF-G} & \bf{WTMF} & \bf{WTMF-G} & \bf{WTMF} & \bf{WTMF-G} \\ \hline
            manual     & 0.7293 & 0.7854 & 0.6187 & 0.6756 & 0.8193 & 0.8775 \\ \hline
            auto       & 0.8640 & 0.8685 & 0.8096 & 0.8149 & 0.9148 & 0.9195 \\ \hline
            total      & 0.8196 & 0.8487 & 0.7452 & 0.7828 & 0.8851 & 0.9049 \\ \hline
            cutted     & 0.8630 & 0.8816 & 0.8045 & 0.8204 & 0.9118 & 0.9279 \\ \hline
            manual\_nt & 0.6194 & 0.7000 & 0.4733 & 0.5502 & 0.7223 & 0.8217 \\ \hline
            auto\_nt   & 0.5297 & 0.5695 & 0.4436 & 0.4798 & 0.5750 & 0.6099 \\ \hline
            total\_nt  & 0.5729 & 0.6341 & 0.4587 & 0.5143 & 0.6448 & 0.7296 \\ \hline
            cutted\_nt & 0.6495 & 0.7039 & 0.5371 & 0.5974 & 0.7372 & 0.7840 \\ \hline
        \end{tabular}
    \end{table}

    Как видно из таблицы~\ref{tabular:wtmf_wmtfg} алгоритм WMTF-G показывает стабильно более высокий результат чем алгоритм WMTF,
    из этого можно сделать вывод, что добавление связей текст-текст позволяет построить более точные рекомендации.

    Сравним два метода рекомендаций: TF-IDF и WTMF-G. Сначала посмотрим на результаты полученные на 
    базовых эталонных наборах данных, то есть тех, которые наряду с нетривиальными содержат большое количество тривиальных связей.
    Результаты тестирования приведены в таблице~\ref{tabular:tfidf_wmtfg}.

    \begin{table}[ht!]
    %\small
    \caption{Cравнительное тестирование алгоритмов TF-IDF и WTMF-G на базовых эталонных наборах данных. \bigskip}
    \centering

    \label{tabular:tfidf_wmtfg}
        \begin{tabular}{|c|c|c|c|c|c|c|}
            \hline
            \bf{\multirow{2}{*}{\specialcell{Набор данных}}} &
            \multicolumn{2}{|c|}{\bf{Метрика MRR}} &
            \multicolumn{2}{|c|}{\bf{Метрика $TOP_1$}} &
            \multicolumn{2}{|c|}{\bf{Метрика $TOP_3$}} \\ \cline{2-7}
            & \bf{TF-IDF} & \bf{WTMF-G} & \bf{TF-IDF} & \bf{WTMF-G} & \bf{TF-IDF} & \bf{WTMF-G} \\ \hline
            manual & 0.8310 & 0.7854 & 0.7337 & 0.6756 & 0.9137 & 0.8775 \\ \hline
            auto   & 0.8817 & 0.8685 & 0.8344 & 0.8149 & 0.9299 & 0.9195 \\ \hline
            total  & 0.8610 & 0.8487 & 0.8044 & 0.7828 & 0.9249 & 0.9049 \\ \hline
            cutted & 0.9075 & 0.8816 & 0.8499 & 0.8204 & 0.9453 & 0.9279 \\ \hline
        \end{tabular}
    \end{table}

    Как видно из таблицы~\ref{tabular:tfidf_wmtfg} метод TF-IDF показывает заметно более лучший результат на всех наборах данных.
    В целом для метода TF-IDF получены неожиданно высокие результаты, качество полученное для метода TF-IDF авторами метода WTMF-G при связывании твитов и новостей почти в два раза меньше~(качество полученное авторами метода WTMF-G приведено в разделе \ref{subsubsec:wtmfg_review}).
    Настолько высокие результаты метода TF-IDF получены по следующим причинам: во-первых, в русском твиттере очень много тривиальных связей твит-новость,
    во-вторых, ввиду специфики русского сегмента твиттер, в заголовках новостей и твитах их описывающих оказалось большое количество общих слов.

    С целью нивелирования влияния тривиальных связей было проведено тестирование на наборах данных, которые содержат исключительно нетривиальные связи.
    Результаты экспериментов приведены в таблице~\ref{tabular:tfidf_wmtfg_nt}.

    \begin{table}[ht!]
    %\small
    \caption{Cравнительное тестирование алгоритмов TF-IDF и WTMF-G на наборах данных с нетривиальными твитами. \bigskip}
    \centering

    \label{tabular:tfidf_wmtfg_nt}
        \begin{tabular}{|c|c|c|c|c|c|c|}
            \hline
            \bf{\multirow{2}{*}{\specialcell{Набор данных}}} &
            \multicolumn{2}{|c|}{\bf{Метрика MRR}} &
            \multicolumn{2}{|c|}{\bf{Метрика $TOP_1$}} &
            \multicolumn{2}{|c|}{\bf{Метрика $TOP_3$}} \\ \cline{2-7}
            & \bf{TF-IDF} & \bf{WTMF-G} & \bf{TF-IDF} & \bf{WTMF-G} & \bf{TF-IDF} & \bf{WTMF-G} \\ \hline
            manual\_nt & 0.7565 & 0.7000 & 0.6250 & 0.5502 & 0.8688 & 0.8217 \\ \hline
            auto\_nt   & 0.6035 & 0.5695 & 0.5254 & 0.4798 & 0.6461 & 0.6099 \\ \hline
            total\_nt  & 0.6914 & 0.6341 & 0.5833 & 0.5143 & 0.8688 & 0.7296 \\ \hline
            cutted\_nt & 0.7485 & 0.7039 & 0.6442 & 0.5974 & 0.8303 & 0.7840 \\ \hline
        \end{tabular}
    \end{table}

    Как видно из таблицы~\ref{tabular:tfidf_wmtfg_nt} на наборах данных с нетривиальными твитами наблюдается такой же результат, как и для наборов данных с полным набором твитов.
    То есть метод TF-IDF во всех рассматриваемых случаях показывает более высокое качество, чем метод WTMF-G.
    Из этого следует, что рассматриваемые нетривиальные твиты, оказались <<большими>> текстами, очень похожими на заголовки новостей~---~это вызвано влиянием специфики русского сегмента
    твиттера.

    Также из таблиц~\ref{tabular:tfidf_wmtfg} и \ref{tabular:tfidf_wmtfg_nt} можно оценить влияние различных наборов данных.
    Автоматически собранный датасет для полного набора твитов даёт более лучшее качество, чем в ручную собранный, это вызвано влиянием большого числа тривиальных связей. Как и ожидается
    результаты на наборах данных с нетривиальными твитами показывают обратную картину.

    На наборе данных cutted для полного набора данных разница качества между TF-IDF и WTMF-G наименьшая - это вызвано тем, что оптимизация метода WTMF-G производилась на этом наборе данных.

%    manual & 0.0456 \\ \hline
%auto & 0.0132 \\ \hline
%total & 0.0123 \\ \hline
%cutted & 0.0259 \\ \hline
%manual\_nt & 0.0565 \\ \hline
%auto\_nt & 0.0340 \\ \hline
%total\_nt & 0.0573 \\ \hline
%cutted\_nt & 0.0446 \\ \hline
