{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-04-08 13:26:11.629313: Start of loading news from /home/avybornov/twnews_data/rss\n",
      "2016-04-08 13:26:11.804761: News successfully loaded\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from twnews.wtmf.text_processors import Lemmatizer\n",
    "from twnews.dataset.storage import TweetsStorage, NewsStorage\n",
    "\n",
    "news_storage = news_storage = NewsStorage()\n",
    "texts = news_storage.get_texts()\n",
    "#/var/log/twnews.log\n",
    "#constants\n",
    "wm = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-04-08 13:26:25.274805: Function split_texts_to_lemmas started with time measure\n",
      "2016-04-08 13:26:25.333096: Function split_texts_to_lemmas finished in 0m0.0580670833588s\n"
     ]
    }
   ],
   "source": [
    "# lemmatize\n",
    "lemmatizer = Lemmatizer()\n",
    "lemmas_list = lemmatizer.split_texts_to_lemmas(texts[:10])\n",
    "lemmatized_texts = [' '.join(lemma) for lemma in lemmas_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Политолог: Россия стремится к миру в Сирии, сокращая группировку войск\n",
      "политолог россия стремиться мир сирия сокращать группировка войско\n",
      "Пресс-конференция по итогам визита на Кубу Барака Обамы\n",
      "пресс-конференция итог визит куб барак обама\n",
      "Президент Кипра соболезнует в связи с катастрофой в Ростове-на-Дону\n",
      "президент кипр соболезновать связь катастрофа ростов-на-дону\n"
     ]
    }
   ],
   "source": [
    "print texts[0]\n",
    "print lemmatized_texts[0]\n",
    "\n",
    "print texts[1]\n",
    "print lemmatized_texts[1]\n",
    "\n",
    "print texts[3]\n",
    "print lemmatized_texts[3]\n",
    "\n",
    "# build X and corpus\n",
    "#tvf = TfidfVectorizer()\n",
    "#tfidf_matrix = tvf.fit_transform(texts)\n",
    "\n",
    "#X = tfidf_matrix.transpose()\n",
    "#corpus = tvf.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from twnews.timeit import timeit\n",
    "\n",
    "@timeit\n",
    "def build_weight_matrix(matrix):\n",
    "    '''Slow and ugly realization TODO: rewrite'''\n",
    "    F = X.copy().todense().tolist()    \n",
    "    W = []\n",
    "    rows = len(F)\n",
    "    columns = len(F[0])\n",
    "\n",
    "    for i in range(rows):\n",
    "        row = [1 if F[i][j] != 0.0 else wm for j in range(columns)]\n",
    "        W.append(row)\n",
    "    return np.array(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-04-06 11:21:28.000228: Function build_weight_matrix started with time measure\n",
      "2016-04-06 11:21:48.301272: Function build_weight_matrix finished in 0m20.3007771969s\n"
     ]
    }
   ],
   "source": [
    "# build weight matrix\n",
    "W = build_weight_matrix(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7084 14416\n"
     ]
    }
   ],
   "source": [
    "texts_num = len(texts)\n",
    "words_num = len(corpus)\n",
    "dim = 10\n",
    "print texts_num, words_num\n",
    "import pickle\n",
    "with open('/tmp/unused', 'wb') as f:\n",
    "    pickle.dump(X,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#init_model\n",
    "P = np.random.rand(dim, words_num)\n",
    "Q = np.random.rand(dim, texts_num)\n",
    "P = P*0.2-0.1\n",
    "Q = Q*0.2-0.1\n",
    "\n",
    "x = np.array(X.copy().todense().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old 2.51062297821 secs\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "def iteration(P,Q,W,l=20):\n",
    "    from time import time    \n",
    "    from scipy import sparse\n",
    "    \n",
    "    new_P = P.copy()\n",
    "    new_Q = Q.copy()\n",
    "    \n",
    "    lI = np.identity(dim)*l\n",
    "    \n",
    "    start = time()\n",
    "    \n",
    "#     for i in range(20):\n",
    "#         print 'start build P'\n",
    "#         lW_i = list(W[i])\n",
    "#         W_i = sparse.spdiags([lW_i], [0], len(lW_i), len(lW_i))\n",
    "                \n",
    "#         A = np.array(np.linalg.inv(np.dot(np.dot(Q,W_i),Q.T)+lI))\n",
    "    \n",
    "    start = time()\n",
    "    for i in range(1):#P.shape[1]\n",
    "        #print 'start build P'\n",
    "        W_i = np.diag(list(W[i]))\n",
    "        A0 = np.dot(np.dot(Q,W_i),Q.T)\n",
    "        A = np.array(np.linalg.inv(A0+lI))\n",
    "        #B = np.dot(np.dot(Q,W_i),x[i,:].T)\n",
    "        #P_i = np.dot(A,B)\n",
    "        #new_P[:,i]=P_i\n",
    "        #print '%dth iteration' % i\n",
    "    end = time()    \n",
    "    print 'old %s secs' % (end - start)\n",
    "    Q_1 = sparse.csr_matrix(Q)\n",
    "    start = time()\n",
    "    for i in range(20):#P.shape[1]\n",
    "        lW_i = list(W[i])\n",
    "        W_i = sparse.spdiags([lW_i], [0], len(lW_i), len(lW_i))\n",
    "        A00 = np.dot(Q_1,W_i)\n",
    "        A00 = np.array(A00)\n",
    "        print A00.shape\n",
    "        #print Q_1.T.shape\n",
    "        A0 = np.dot(A00,Q.T)\n",
    "        A = np.array(np.linalg.inv(A0+lI))\n",
    "        \n",
    "        #B = np.dot(np.dot(Q,W_i),x[i,:].T)\n",
    "        #P_i = np.dot(A,B)\n",
    "        #new_P[:,i]=P_i\n",
    "        #print '%dth iteration' % i\n",
    "    end = time()    \n",
    "    print 'new %s secs' % (end - start)\n",
    "    \n",
    "#     print 'start build Q'\n",
    "#     for j in range(Q.shape[1]):\n",
    "#         W_j = np.diag(list(W[:,j]))    \n",
    "#         A = np.array(np.linalg.inv(np.dot(np.dot(P,W_j),P.T)+lI))\n",
    "#         #B = np.dot(np.dot(P,W_j),x[:,j].T)\n",
    "#         #Q_j = np.dot(A,B)\n",
    "#         #new_Q[:,j]=Q_j\n",
    "#         break\n",
    "    end = time()    \n",
    "    print 'old %s secs' % (end - start)\n",
    "#         if j%1000 == 0:\n",
    "#             print '%dth iteration' % j\n",
    "        \n",
    "    return new_P,new_Q\n",
    "\n",
    "P,Q = iteration(P,Q,W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
